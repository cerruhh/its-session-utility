app.js: // Frontend logic: menu actions, keyboard shortcuts, rendering let state = { loaded: false, chunkIndex: null, data: null, showDisplayNames: false, fileCount: 0, imagesReloadKey: Date.now(), }; let markMode = false; let markedMessages = new Set(); let lastClickedIndex = null; let dividerMode = false; let pendingDivider = null; // waiting for second divider let groups = []; // [{start, end, group, color}] let groupAssignments = new Map(); // key -> groupNum let groupColors = {}; // groupNum -> color string let groupNames = {}; // groupId -> name (optional) const fileInput = document.getElementById('file-input'); const canvas = document.getElementById('canvas'); const bottombar = document.getElementById('bottombar'); const showDisplayCheckbox = document.getElementById('show-display-names'); // Helpers function setBottomBar(text){ bottombar.textContent = text } function formatDate(ts){ try{ const d = new Date(ts); const dd = String(d.getDate()).padStart(2,'0'); const mm = String(d.getMonth()+1).padStart(2,'0'); const yyyy = d.getFullYear(); return ${dd}/${mm}/${yyyy}; }catch(e){ return ts } } function clearCanvas(){ // Remove all children to avoid memory accumulation while(canvas.firstChild) canvas.removeChild(canvas.firstChild); } function renderMessage(msg) { let text = msg.content || ""; // Make links clickable text = text.replace(/(https?:\/\/[^\s]+)/g, '<a href="$1" target="_blank">$1</a>'); // Handle db://attachments/... links text = text.replace(/db:\/\/attachments\/([A-Za-z0-9_-]+)/g, '<a href="/attachment/$1" target="_blank">[attachment]</a>'); return <div class="message">${text}</div>; } function randomLightColor() { const r = Math.floor(150 + Math.random() * 105); const g = Math.floor(150 + Math.random() * 105); const b = Math.floor(150 + Math.random() * 105); return rgb(${r},${g},${b}); } function jumpToDivider(direction) { const keys = groups.flatMap(g => [g.start, g.end]); const currentPos = getCurrentVisibleMessageKey(); const idx = keys.indexOf(currentPos); if (idx >= 0) { const target = keys[idx + direction]; if (target) scrollToMessage(target); } } function renderChunk(data) { clearCanvas(); if (!data || !data.messages) { setBottomBar( "Chunk " + (state.chunkIndex ?? "-") + " | messageCount: " + (data ? data.messageCount ?? 0 : 0) ); return; } const messages = data.messages; // ✅ clear marks for this chunk only messages.forEach((msg, i) => { const key = ${state.chunkIndex}:${i}; if (msg.marked) { markedMessages.add(key); } else { markedMessages.delete(key); } // ✅ restore group assignments if (msg.group) { groupAssignments.set(key, msg.group); if (!groupColors[msg.group]) { groupColors[msg.group] = randomLightColor(); } } else { groupAssignments.delete(key); } }); messages.forEach((msg, i) => { const el = document.createElement("div"); el.className = "message"; const key = ${state.chunkIndex}:${i}; // ✅ highlight if marked if (markedMessages.has(key)) { el.classList.add("marked"); } // ✅ apply group color if assigned if (groupAssignments.has(key)) { const groupNum = groupAssignments.get(key); const color = groupColors[groupNum] || randomLightColor(); groupColors[groupNum] = color; el.style.borderLeft = 4px solid ${color}; el.dataset.group = groupNum; } // date const dateEl = document.createElement("div"); dateEl.className = "msg-date"; dateEl.textContent = formatDate(msg.timestamp || ""); // content const contentEl = document.createElement("div"); contentEl.className = "msg-content"; const author = document.createElement("div"); author.className = "msg-author"; const name = state.showDisplayNames ? msg.author?.nickname || msg.author?.name : msg.author?.name || msg.author?.nickname || ""; author.textContent = ${name}:; const text = document.createElement("div"); text.className = "msg-text"; text.innerHTML = marked.parse(msg.content || ""); contentEl.appendChild(author); contentEl.appendChild(text); // attachments if (Array.isArray(msg.attachments) && msg.attachments.length > 0) { const acont = document.createElement("div"); acont.className = "attachment"; msg.attachments.forEach((att) => { const url = "/attachment/" + encodeURIComponent(att.replace(/^db:\/\//, "")) + "?v=" + state.imagesReloadKey; const img = document.createElement("img"); img.style.maxWidth = "300px"; img.style.display = "block"; img.style.marginTop = "6px"; img.src = url; img.onerror = () => { img.style.display = "none"; }; acont.appendChild(img); }); contentEl.appendChild(acont); } el.appendChild(dateEl); el.appendChild(contentEl); // ✅ Interactions el.addEventListener("click", (ev) => { if (markMode) { // mark/unmark if (ev.shiftKey && lastClickedIndex !== null) { const start = Math.min(lastClickedIndex, i); const end = Math.max(lastClickedIndex, i); for (let j = start; j <= end; j++) { const k = ${state.chunkIndex}:${j}; markedMessages.add(k); const msgEl = canvas.children[j]; if (msgEl) msgEl.classList.add("marked"); } } else { if (markedMessages.has(key)) { markedMessages.delete(key); el.classList.remove("marked"); } else { markedMessages.add(key); el.classList.add("marked"); } } lastClickedIndex = i; ev.stopPropagation(); updateBottomBar(); } else if (dividerMode) { // divider mode → place start/end if (!pendingDivider) { pendingDivider = key; } else { const groupNum = Math.max(0, ...Object.keys(groupColors).map(Number)) + 1; const color = randomLightColor(); groupColors[groupNum] = color; const [cidx1, mi1] = pendingDivider.split(":").map(Number); const [cidx2, mi2] = key.split(":").map(Number); if (cidx1 === cidx2 && cidx1 === state.chunkIndex) { const start = Math.min(mi1, mi2); const end = Math.max(mi1, mi2); for (let j = start; j <= end; j++) { const k = ${state.chunkIndex}:${j}; groupAssignments.set(k, groupNum); const msgEl = canvas.children[j]; if (msgEl) { msgEl.style.borderLeft = 4px solid ${color}; msgEl.dataset.group = groupNum; } } } pendingDivider = null; updateBottomBar(); } } }); el.addEventListener("contextmenu", (ev) => { if (markMode) { markedMessages.delete(key); el.classList.remove("marked"); ev.preventDefault(); updateBottomBar(); } else if (dividerMode && groupAssignments.has(key)) { // remove divider assignment const groupNum = groupAssignments.get(key); groupAssignments.delete(key); el.style.borderLeft = ""; el.removeAttribute("data-group"); ev.preventDefault(); updateBottomBar(); } }); canvas.appendChild(el); }); updateBottomBar(); } function updateBottomBar(){ let text = 'No file loaded'; if(state.loaded && state.data){ const count = state.data.messageCount ?? state.data.messages.length; text = Chunk ${state.chunkIndex} | messageCount: ${count}; } if(markMode){ text += ' | markmode enabled'; } if(dividerMode){ text += ' | dividermode enabled'; } setBottomBar(text); } // Networking async function doUploadFile(file){ const fd = new FormData(); fd.append('file', file); const res = await fetch('/upload', {method:'POST', body:fd}); if(!res.ok){ const err = await res.json().catch(()=>({error:'upload failed'})); alert('Upload error: ' + (err.error || 'unknown')); return; } const data = await res.json(); state.loaded = true; state.chunkIndex = data.chunk_index; state.fileCount = data.file_count || 0; state.data = data.data; renderChunk(state.data); } async function navigate(direction){ if(!state.loaded){ alert('No file loaded'); return } const res = await fetch('/navigate', {method:'POST', headers:{'Content-Type':'application/json'}, body: JSON.stringify({direction})}); if(!res.ok){ const e = await res.json().catch(()=>({error:'nav failed'})); alert(e.error||'navigate failed'); return } const j = await res.json(); state.chunkIndex = j.chunk_index; state.fileCount = j.file_count || state.fileCount; state.data = j.data; renderChunk(state.data); } async function reloadChunk(){ if(!state.loaded){ alert('No file loaded'); return } const res = await fetch('/get_chunk'); if(!res.ok){ const e = await res.json().catch(()=>({error:'reload failed'})); alert(e.error||'reload failed'); return } const j = await res.json(); state.chunkIndex = j.chunk_index; state.fileCount = j.file_count || state.fileCount; state.data = j.data; renderChunk(state.data); } async function savePacked(){ if(!state.loaded){ alert('No file loaded'); return; } // marks const marks = Object.fromEntries([...markedMessages].map(k => [k, true])); // groups: build mapping of key -> {id,name,color} const groupPayload = { assignments: {} }; for (const [key, gid] of groupAssignments.entries()) { groupPayload.assignments[key] = { id: gid, name: groupNames[gid] || null, color: groupColors[gid] || null }; } const res = await fetch('/save_marked', { method: 'POST', headers: {'Content-Type':'application/json'}, body: JSON.stringify({marks, groups: groupPayload}) }); if(!res.ok){ const e = await res.json().catch(()=>({error:'save failed'})); alert(e.error||'Save failed'); return; } const j = await res.json(); alert('Marked messages & groups saved to SAVE_FOLDER.'); } async function exportMarked() { if (!state.loaded) { alert("No file loaded"); return; } const marks = {}; markedMessages.forEach(k => { marks[k] = true; }); const groupsPayload = { assignments: {} }; for (const [key, gid] of groupAssignments.entries()) { groupsPayload.assignments[key] = { id: gid, name: groupNames[gid] || null, color: groupColors[gid] || null }; } const res = await fetch("/export_marked", { method: "POST", headers: { "Content-Type": "application/json" }, body: JSON.stringify({ marks, groups: groupsPayload }) }); if (!res.ok) { const e = await res.json().catch(() => ({ error: "Export failed" })); alert(e.error || "Export failed"); return; } const blob = await res.blob(); const url = URL.createObjectURL(blob); const a = document.createElement("a"); a.href = url; a.download = "marked_export.zip"; document.body.appendChild(a); a.click(); a.remove(); URL.revokeObjectURL(url); } // Assuming your button has an id="exportBtn" const exportBtn = document.getElementById("menu-export-save"); if (exportBtn) { exportBtn.addEventListener("click", exportMarked); } function reloadImages(){ // Just bump a cachebust key and rerender to force image reload state.imagesReloadKey = Date.now(); if(state.data) renderChunk(state.data); } // UI wiring // File menu document.getElementById('menu-load').addEventListener('click', ()=> fileInput.click()); fileInput.addEventListener('change', async (ev)=>{ const f = ev.target.files[0]; if(f) await doUploadFile(f); fileInput.value = ''; }); document.getElementById('menu-save-marked').addEventListener('click', savePacked); // View menu document.getElementById('menu-reload-images').addEventListener('click', reloadImages); showDisplayCheckbox.addEventListener('change', (e)=>{ state.showDisplayNames = e.target.checked; if(state.data) renderChunk(state.data); }); // Chunk menu actions document.querySelectorAll('[data-action]').forEach(el=>{ el.addEventListener('click', ()=>{ const action = el.getAttribute('data-action'); navigate(action); }) }); const menuLoadRecent = document.getElementById('menu-load-recent'); async function refreshRecentMenu(){ const res = await fetch('/list_recents'); if(!res.ok) return; const recents = await res.json(); menuLoadRecent.innerHTML = ''; if(recents.length === 0){ const li = document.createElement('div'); li.textContent = '(none)'; li.className = 'menu-disabled'; menuLoadRecent.appendChild(li); return; } recents.forEach(folder=>{ const li = document.createElement('div'); li.textContent = folder; li.className = 'menu-item'; li.addEventListener('click', ()=> loadRecent(folder)); menuLoadRecent.appendChild(li); }); } async function loadRecent(folder){ const res = await fetch('/load_recent', { method: 'POST', headers: {'Content-Type':'application/json'}, body: JSON.stringify({folder}) }); if(!res.ok){ const e = await res.json().catch(()=>({error:'load recent failed'})); alert(e.error||'failed to load recent'); return; } const j = await res.json(); state.loaded = true; state.chunkIndex = j.chunk_index; state.data = j.data; renderChunk(state.data); } // refresh submenu when app loads refreshRecentMenu(); const menuLoadRecentSave = document.getElementById('menu-load-recent-save'); async function refreshRecentSaveMenu(){ const res = await fetch('/list_recent_saves'); if(!res.ok) return; const recents = await res.json(); menuLoadRecentSave.innerHTML = ''; if(recents.length === 0){ const li = document.createElement('div'); li.textContent = '(none)'; li.className = 'menu-disabled'; menuLoadRecentSave.appendChild(li); return; } recents.forEach(folder=>{ const li = document.createElement('div'); li.textContent = folder; li.className = 'menu-item'; li.addEventListener('click', ()=> loadRecentSave(folder)); menuLoadRecentSave.appendChild(li); }); } function handleDividerClick(idx, mi) { const key = ${idx}:${mi}; if (!pendingDivider) { pendingDivider = key; // wait for second divider } else { // assign group const groupNum = groups.length + 1; const color = randomLightColor(); groups.push({start: pendingDivider, end: key, group: groupNum, color}); pendingDivider = null; renderChunk(state.data); } } async function loadRecentSave(folder){ const path = folder; // backend will prepend SAVE_FOLDER const res = await fetch('/load_recent', { method: 'POST', headers: {'Content-Type':'application/json'}, body: JSON.stringify({folder: path, save_folder:true}) // optional flag }); if(!res.ok){ const e = await res.json().catch(()=>({error:'load recent save failed'})); alert(e.error||'Failed to load save'); return; } const j = await res.json(); state.loaded = true; state.chunkIndex = j.chunk_index; state.data = j.data; markedMessages.clear(); // reset marks when loading previous save renderChunk(state.data); } // call once on startup refreshRecentSaveMenu(); // Keyboard shortcuts window.addEventListener('keydown', (e)=>{ if(e.ctrlKey && !e.altKey){ // ctrl+l -> load if(e.key.toLowerCase()==='l'){ e.preventDefault(); fileInput.click(); return; } // ctrl+s -> save if(e.key.toLowerCase()==='s'){ e.preventDefault(); savePacked(); return; } // ctrl+ArrowUp -> first if(e.key === 'ArrowUp'){ e.preventDefault(); navigate('first'); return; } // ctrl+ArrowDown -> last if(e.key === 'ArrowDown'){ e.preventDefault(); navigate('last'); return; } // ctrl+ArrowRight -> forward if(e.key === 'ArrowRight'){ e.preventDefault(); navigate('forward'); return; } // ctrl+ArrowLeft -> backward if(e.key === 'ArrowLeft'){ e.preventDefault(); navigate('backward'); return; } // ctrl+r -> reload chunk if(e.key.toLowerCase()==='r' && !e.shiftKey){ e.preventDefault(); reloadChunk(); return; } // ctrl+1 -> toggle mark mode if(e.ctrlKey && e.key === '1'){ e.preventDefault(); markMode = !markMode; updateBottomBar(); return; } if (e.ctrlKey && e.key === "2") { markMode = false; dividerMode = !dividerMode; pendingDivider = null; updateBottomBar(); // show "Divider mode" in bottom right } } // ctrl+shift+r -> reload images if(e.ctrlKey && e.shiftKey && e.key.toLowerCase()==='r'){ e.preventDefault(); reloadImages(); return; } }); // initial status setBottomBar('No file loaded'); app.py: import io import json import logging import os import shutil import sqlite3 import zipfile import re # from datetime import datetime from flask import Flask, render_template, request, jsonify, send_file, session, abort app = Flask(__name__) app.secret_key = "supersecretkey" UPLOAD_FOLDER = "uploads" EXTRACT_FOLDER = "extracted" SAVE_FOLDER = "saved" os.makedirs(UPLOAD_FOLDER, exist_ok=True) os.makedirs(EXTRACT_FOLDER, exist_ok=True) os.makedirs(SAVE_FOLDER, exist_ok=True) logging.basicConfig(level=logging.INFO) @app.route("/") def index(): return render_template("index.html") def sort_json_files(files): # Sort by the first integer found in filename; if none, fall back to filename def keyfn(f): m = re.search(r'(\d+)', f) return (int(m.group(1)), f) if m else (float('inf'), f) return sorted(files, key=keyfn) @app.route("/upload", methods=["POST"]) def upload(): file = request.files.get("file") if not file or not file.filename.endswith(".zip"): return jsonify({"error": "Invalid file format"}), 400 filepath = os.path.join(UPLOAD_FOLDER, file.filename) file.save(filepath) extract_path = os.path.join(EXTRACT_FOLDER, os.path.splitext(file.filename)[0]) if os.path.exists(extract_path): for root, dirs, files in os.walk(extract_path, topdown=False): for name in files: os.remove(os.path.join(root, name)) for name in dirs: os.rmdir(os.path.join(root, name)) with zipfile.ZipFile(filepath, 'r') as z: z.extractall(extract_path) json_files = [f for f in os.listdir(extract_path) if f.endswith(".json")] json_files = sort_json_files(json_files) db_files = [f for f in os.listdir(extract_path) if f.endswith(".db")] if not json_files or "packed_images.db" not in db_files: return jsonify({"error": "Invalid archive: needs .json files and packed_images.db"}), 400 session["json_files"] = json_files session["extract_path"] = extract_path session["current_index"] = 0 session["file_count"] = len(json_files) data = load_chunk(0) return jsonify({ "message": "File loaded", "chunk_index": 0, "file_count": len(json_files), "data": data }) def load_chunk(idx): json_files = session.get("json_files", []) extract_path = session.get("extract_path") if not json_files or not extract_path: return None # ensure index is in bounds idx = max(0, min(idx, len(json_files) - 1)) path = os.path.join(extract_path, json_files[idx]) with open(path, "r", encoding="utf-8") as f: data = json.load(f) # include message count for UI convenience data["messageCount"] = len(data.get("messages", [])) return data @app.route("/get_chunk") def get_chunk(): idx = session.get("current_index", 0) data = load_chunk(idx) if not data: return jsonify({"error": "No file loaded"}), 400 return jsonify({"chunk_index": idx, "file_count": session.get("file_count", len(session.get("json_files", []))), "data": data}) # Recents @app.route("/list_recents") def list_recents(): # list directories inside extracted/ recents = [] for name in sorted(os.listdir(EXTRACT_FOLDER)): path = os.path.join(EXTRACT_FOLDER, name) if os.path.isdir(path): json_files = [f for f in os.listdir(path) if f.endswith(".json")] db_files = [f for f in os.listdir(path) if f.endswith(".db")] if json_files and "packed_images.db" in db_files: recents.append(name) return jsonify(recents) @app.route("/list_recent_saves") def list_recent_saves(): # list directories inside SAVE_FOLDER recents = [] for name in sorted(os.listdir(SAVE_FOLDER)): path = os.path.join(SAVE_FOLDER, name) if os.path.isdir(path): json_files = [f for f in os.listdir(path) if f.endswith(".json")] db_files = [f for f in os.listdir(path) if f.endswith(".db")] if json_files and "packed_images.db" in db_files: recents.append(name) return jsonify(recents) @app.route("/export_marked", methods=["POST"]) def export_marked(): marks = request.json.get("marks", {}) groups = request.json.get("groups", {}) group_assignments = groups.get("assignments", {}) extract_path = session.get("extract_path") if not extract_path: return jsonify({"error": "No file loaded"}), 400 import tempfile, zipfile, shutil, sqlite3, os, json from flask import send_file def attachment_id_from_ref(ref: str) -> str: s = ref or "" if s.startswith("db://"): s = s[5:] if s.startswith("attachments/"): s = s.split("/", 1)[1] return s with tempfile.TemporaryDirectory() as tmpdir: used_attachment_ids = set() chunk_files = [] for idx, fname in enumerate(session["json_files"]): src = os.path.join(extract_path, fname) with open(src, "r", encoding="utf-8") as f: data = json.load(f) new_messages = [] for mi, msg in enumerate(data.get("messages", [])): key = f"{idx}:{mi}" if key in marks: # copy message and include its group if present in payload new_msg = msg.copy() if key in group_assignments: ga = group_assignments[key] # store group object new_msg["group"] = {} if "id" in ga: new_msg["group"]["id"] = ga["id"] if "name" in ga: new_msg["group"]["name"] = ga["name"] if "color" in ga: new_msg["group"]["color"] = ga["color"] else: new_msg.pop("group", None) new_messages.append(new_msg) # collect referenced attachments for att in msg.get("attachments", []) or []: aid = attachment_id_from_ref(att) if aid: used_attachment_ids.add(aid) if new_messages: data["messages"] = new_messages new_fname = f"{len(chunk_files)}.json" dst = os.path.join(tmpdir, new_fname) with open(dst, "w", encoding="utf-8") as f: json.dump(data, f, ensure_ascii=False, indent=2) chunk_files.append(new_fname) # Copy DB and remove unreferenced attachments db_src = os.path.join(extract_path, "packed_images.db") db_dst = os.path.join(tmpdir, "packed_images.db") if os.path.exists(db_src): shutil.copy(db_src, db_dst) conn = sqlite3.connect(db_dst) c = conn.cursor() if used_attachment_ids: placeholders = ",".join("?" for _ in used_attachment_ids) c.execute( f"DELETE FROM attachments WHERE id NOT IN ({placeholders})", tuple(used_attachment_ids), ) else: c.execute("DELETE FROM attachments") conn.commit() c.execute("VACUUM") conn.commit() conn.close() else: # If no DB, create an empty attachments DB to avoid missing file in zip conn = sqlite3.connect(db_dst) c = conn.cursor() c.execute("CREATE TABLE attachments (id TEXT PRIMARY KEY, file_name TEXT, mime_type TEXT, data BLOB)") conn.commit() conn.close() # create zip zip_path = os.path.join(tmpdir, "marked_export.zip") with zipfile.ZipFile(zip_path, "w", zipfile.ZIP_DEFLATED) as zipf: for f in chunk_files: zipf.write(os.path.join(tmpdir, f), arcname=f) zipf.write(db_dst, arcname="packed_images.db") return send_file(zip_path, as_attachment=True, download_name="marked_export.zip") @app.route("/load_recent", methods=["POST"]) def load_recent(): folder = request.json.get("folder") use_save_folder = request.json.get("save_folder", False) base_folder = SAVE_FOLDER if use_save_folder else EXTRACT_FOLDER extract_path = os.path.join(base_folder, folder) if not os.path.exists(extract_path): return jsonify({"error": "Folder not found"}), 404 json_files = [f for f in os.listdir(extract_path) if f.endswith(".json")] json_files = sort_json_files(json_files) db_files = [f for f in os.listdir(extract_path) if f.endswith(".db")] if not json_files or "packed_images.db" not in db_files: return jsonify({"error": "Invalid folder"}), 400 session["json_files"] = json_files session["extract_path"] = extract_path session["current_index"] = 0 session["file_count"] = len(json_files) data = load_chunk(0) return jsonify({"message": "Recent loaded", "chunk_index": 0, "file_count": len(json_files), "data": data}) @app.route("/navigate", methods=["POST"]) def navigate(): direction = request.json.get("direction") json_files = session.get("json_files", []) if not json_files: return jsonify({"error": "No file loaded"}), 400 idx = session.get("current_index", 0) if idx is None or idx < 0 or idx >= len(json_files): idx = 0 if direction == "first": idx = 0 elif direction == "last": idx = len(json_files) - 1 elif direction == "forward": idx = min(idx + 1, len(json_files) - 1) elif direction == "backward": idx = max(idx - 1, 0) elif direction == "reload": pass session["current_index"] = idx data = load_chunk(idx) return jsonify({"chunk_index": idx, "file_count": len(json_files), "data": data}) @app.route('/attachment/<path:attachment_id>') def get_attachment(attachment_id): db_path = os.path.join(session["extract_path"], 'packed_images.db') if not os.path.exists(db_path): return jsonify({"error": "Database not found", "info": f"upload_folder: {db_path} , extract_folder: {session["extract_path"]}"}), 404 conn = sqlite3.connect(db_path) c = conn.cursor() # ✅ only use the last segment if prefixed with "attachments/" if attachment_id.startswith("attachments/"): attachment_id = attachment_id.split("/", 1)[1] c.execute("SELECT file_name, mime_type, data FROM attachments WHERE id = ?", (attachment_id,)) row = c.fetchone() conn.close() if row: file_name, mime_type, blob = row return send_file(io.BytesIO(blob), mimetype=mime_type, download_name=file_name) else: return jsonify({"error": "Attachment not found"}), 404 @app.route("/attachment/<file_id>") def attachment(file_id): print(file_id) extract_path = session.get("extract_path") logging.info(extract_path) if not extract_path: abort(404) db_path = os.path.join(extract_path, "packed_images.db") if not os.path.exists(db_path): abort(404) conn = sqlite3.connect(db_path) cursor = conn.cursor() cursor.execute("SELECT file_name, mime_type, data FROM attachments WHERE id = ?", (file_id,)) print(file_id) row = cursor.fetchone() conn.close() if not row: abort(404) file_name, mime_type, blob = row return send_file(io.BytesIO(blob), mimetype=mime_type, as_attachment=False, download_name=file_name) @app.route("/save_marked", methods=["POST"]) def save_marked(): marks = request.json.get("marks", {}) groups = request.json.get("groups", {}) # expected: { "assignments": { "0:3": {"id":1,"name":"A","color":"rgb(...)"} } } group_assignments = groups.get("assignments", {}) extract_path = session.get("extract_path") if not extract_path: return jsonify({"error": "No file loaded"}), 400 save_path = os.path.join(SAVE_FOLDER, os.path.basename(extract_path)) os.makedirs(save_path, exist_ok=True) for idx, fname in enumerate(session["json_files"]): src = os.path.join(extract_path, fname) dst = os.path.join(save_path, fname) with open(src, "r", encoding="utf-8") as f: data = json.load(f) for mi, msg in enumerate(data.get("messages", [])): key = f"{idx}:{mi}" # marks if key in marks: msg["marked"] = True else: msg.pop("marked", None) # group assignments: store as object {id,name,color} if key in group_assignments: ga = group_assignments[key] # ensure id exists gid = ga.get("id") gname = ga.get("name") if "name" in ga else None gcolor = ga.get("color") if "color" in ga else None msg["group"] = {"id": gid} if gname is not None: msg["group"]["name"] = gname if gcolor is not None: msg["group"]["color"] = gcolor else: msg.pop("group", None) with open(dst, "w", encoding="utf-8") as f: json.dump(data, f, ensure_ascii=False, indent=2) # copy DB safely db_src = os.path.join(extract_path, "packed_images.db") if os.path.exists(db_src): db_dst = os.path.join(save_path, "packed_images.db") if os.path.abspath(db_src) != os.path.abspath(db_dst): shutil.copy(db_src, db_dst) return jsonify({"message": "Marked data saved"}) @app.route("/export_save", methods=["POST"]) def export_save(): marks = request.json.get("marks", {}) extract_path = session.get("extract_path") if not extract_path: return jsonify({"error": "No file loaded"}), 400 # temp folder import tempfile, shutil temp_dir = tempfile.mkdtemp() # process jsons kept_attachments = set() for idx, fname in enumerate(session["json_files"]): src = os.path.join(extract_path, fname) dst = os.path.join(temp_dir, fname) with open(src, "r", encoding="utf-8") as f: data = json.load(f) new_msgs = [] for mi, msg in enumerate(data.get("messages", [])): key = f"{idx}:{mi}" if key in marks: msg["marked"] = True new_msgs.append(msg) # collect attachment ids for att in msg.get("attachments", []): attid = att.replace("db://attachments/", "") kept_attachments.add(attid) data["messages"] = new_msgs with open(dst, "w", encoding="utf-8") as f: json.dump(data, f, ensure_ascii=False, indent=2) # copy db but only keep kept_attachments db_src = os.path.join(extract_path, "packed_images.db") if os.path.exists(db_src): db_dst = os.path.join(temp_dir, "packed_images.db") conn_src = sqlite3.connect(db_src) conn_dst = sqlite3.connect(db_dst) csrc = conn_src.cursor() cdst = conn_dst.cursor() # recreate schema cdst.execute("CREATE TABLE attachments (id TEXT PRIMARY KEY, file_name TEXT, mime_type TEXT, data BLOB)") for attid in kept_attachments: row = csrc.execute("SELECT id,file_name,mime_type,data FROM attachments WHERE id=?", (attid,)).fetchone() if row: cdst.execute("INSERT INTO attachments VALUES (?,?,?,?)", row) conn_dst.commit() conn_src.close() conn_dst.close() # zip it zip_path = os.path.join(SAVE_FOLDER, "exported.zip") shutil.make_archive(zip_path.replace(".zip", ""), 'zip', temp_dir) shutil.rmtree(temp_dir) return send_file(zip_path, as_attachment=True) if __name__ == "__main__": app.run(debug=True) My problems: Currently, there is something wrong with the last chunk, it doesn't seem to update the bottombar chunk index, also isn't even the last chunk! Make sure the ordering goes from 0-N (43 in my case). It should be lowest value to highest, not anything else. Also, this error occours: :5000/favicon.ico:1 Failed to load resource: the server responded with a status of 404 (NOT FOUND) app.js:162 Uncaught (in promise) TypeError: att.replace is not a function at app.js:162:34 at Array.forEach (<anonymous>) at app.js:159:23 at Array.forEach (<anonymous>) at renderChunk (app.js:112:12) at navigate (app.js:309:3) app.js:162 Uncaught (in promise) TypeError: att.replace is not a function at app.js:162:34 at Array.forEach (<anonymous>) at app.js:159:23 at Array.forEach (<anonymous>) at renderChunk (app.js:112:12) at navigate (app.js:309:3) app.js:162 Uncaught (in promise) TypeError: att.replace is not a function at app.js:162:34 at Array.forEach (<anonymous>) at app.js:159:23 at Array.forEach (<anonymous>) at renderChunk (app.js:112:12) at navigate (app.js:309:3) Ignore favicon 404 Also, i want it so i can name the dividers that i make, so when i make another divider starting from another chunk, it counts to the same divider group. Also could you optimize the function save_marked, it takes forever at the moment. Also console.log or logging.info the currently loaded .json files filename each time a new one is loaded.
